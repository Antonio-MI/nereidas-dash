{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos los paths a las carpetas qeu contienen los datos de las boyas\n",
    "paths = [\"boyasRevisadas/BoyasUPCT/\", \"boyasRevisadas/Boyasprof/\"]\n",
    "\n",
    "# Definimos un diccionario en el que ir guardando en dataframes de cada fichero\n",
    "dataframes_boyas = {}\n",
    "\n",
    "# Diccionario de traducciones\n",
    "nombres_es = {\n",
    "    \"Chlorophyll\": \"Clorofila\",\n",
    "    \"Temperature\": \"Temperatura\",\n",
    "    \"Dissolvedoxygen\": \"OxigenoDisuelto\",\n",
    "    \"Salinity\": \"Salinidad\",\n",
    "    \"Turbidity\": \"Turbidez\"\n",
    "}\n",
    "\n",
    "# Para activar/desactivar nombres en español\n",
    "usar_es = True  # cambia a False para mantener los nombres en inglés\n",
    "\n",
    "# Iteramos para los paths\n",
    "for path in paths: \n",
    "    # Cogemos el identificador de las boyas\n",
    "    buoy_ids = [f for f in os.listdir(path) if os.path.isdir(os.path.join(path, f))]\n",
    "    # Iteramos sobre esos identificadores\n",
    "    for buoy_id in buoy_ids:\n",
    "        # Listamos los csv\n",
    "        archivos_csv = [f for f in os.listdir(path + buoy_id) if f.endswith('.csv')]\n",
    "        # Iteramos sobre los csv\n",
    "        for archivo in archivos_csv:\n",
    "            # Cogemos el nombre de la variable\n",
    "            nombre_variable = os.path.splitext(archivo)[0]\n",
    "            # Y definimos su ruta completa\n",
    "            ruta_completa = os.path.join(path, buoy_id, archivo)\n",
    "            # Condición para que si alguna de las propiedades de interés está en el nombre de la variable \n",
    "            if any(substr in nombre_variable for substr in [\"Chlorophyll\", \"Temperature\", \"Dissolved oxygen\", \"Salinity\", \"Turbidity\"]):\n",
    "                nombre_variable = nombre_variable.replace(\" \", \"\")\n",
    "\n",
    "                # Traducción\n",
    "                if usar_es:\n",
    "                    for en, es in nombres_es.items():\n",
    "                        if en.replace(\" \", \"\") in nombre_variable:\n",
    "                            nombre_variable = nombre_variable.replace(en.replace(\" \", \"\"), es)\n",
    "                            break\n",
    "\n",
    "                # Cargamos csv (con separador por ; e ignorando las primeras filas, que contienen información adicional) y lo guardamos en el diccionario de dataframes\n",
    "                dataframes_boyas[f\"{buoy_id}_{nombre_variable}\"] = pd.read_csv(ruta_completa, skiprows=5, sep=';') \n",
    "\n",
    "# Para cada uno de los dataframes\n",
    "for key, df in dataframes_boyas.items():\n",
    "    try:\n",
    "        # Cogemos la fecha y la ponemos en formato datetime\n",
    "        df['Date'] = pd.to_datetime(df['Date'])\n",
    "    except:\n",
    "        print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E3_Turbidez_E3_UPCT\n",
      "E3_Temperatura_E3_UPCT\n",
      "E3_Clorofila_E3_UPCT\n",
      "E3_OxigenoDisuelto_E3_UPCT\n",
      "E3_Salinidad_E3_UPCT\n",
      "E12_Temperatura_E12_UPCT\n",
      "E12_Salinidad_E12_UPCT\n",
      "E12_Clorofila_E12_UPCT\n",
      "E12_Turbidez_E12_UPCT\n",
      "E12_OxigenoDisuelto_E12_UPCT\n",
      "E9_Clorofila_E9_UPCT\n",
      "E9_OxigenoDisuelto_E9_UPCT\n",
      "E9_Salinidad_E9_UPCT\n",
      "E9_Turbidez_E9_UPCT\n",
      "E9_Temperatura_E9_UPCT\n",
      "E8_Clorofila_E8_UPCT\n",
      "E8_Turbidez_E8_UPCT\n",
      "E8_Temperatura_E8_UPCT\n",
      "E8_OxigenoDisuelto_E8_UPCT\n",
      "E8_Salinidad_E8_UPCT\n",
      "E7_Turbidez_E7_UPCT\n",
      "E7_Temperatura_E7_UPCT\n",
      "E7_Clorofila_E7_UPCT\n",
      "E7_Salinidad_E7_UPCT\n",
      "E7_OxigenoDisuelto_E7_UPCT\n",
      "E4_Temperatura_E4_UPCT\n",
      "E4_Turbidez_E4_UPCT\n",
      "E4_OxigenoDisuelto_E4_UPCT\n",
      "E4_Clorofila_E4_UPCT\n",
      "E4_Salinidad_E4_UPCT\n",
      "E2_Turbidez_E2_UPCT\n",
      "E2_Temperatura_E2_UPCT\n",
      "E2_Salinidad_E2_UPCT\n",
      "E2_OxigenoDisuelto_E2_UPCT\n",
      "E2_Clorofila_E2_UPCT\n",
      "E10_Turbidez_E10_UPCT\n",
      "E10_Temperatura_E10_UPCT\n",
      "E10_Salinidad_E10_UPCT\n",
      "E10_OxigenoDisuelto_E10_UPCT\n",
      "E10_Clorofila_E10_UPCT\n",
      "E6_OxigenoDisuelto_E6_UPCT\n",
      "E6_Clorofila_E6_UPCT\n",
      "E6_Turbidez_E6_UPCT\n",
      "E6_Salinidad_E6_UPCT\n",
      "E6_Temperatura_E6_UPCT\n",
      "E1_Salinidad_E1_UPCT\n",
      "E1_OxigenoDisuelto_E1_UPCT\n",
      "E1_Turbidez_E1_UPCT\n",
      "E1_Clorofila_E1_UPCT\n",
      "E1_Temperatura_E1_UPCT\n",
      "E11_Salinidad_E11_UPCT\n",
      "E11_Clorofila_E11_UPCT\n",
      "E11_OxigenoDisuelto_E11_UPCT\n",
      "E11_Turbidez_E11_UPCT\n",
      "E11_Temperatura_E11_UPCT\n",
      "E12_Clorofila_E12\n",
      "E12_Temperatura_E12\n",
      "E12_Turbidez_E12\n",
      "E12_OxigenoDisuelto_E12\n",
      "E12_Salinidad_E12\n",
      "E9_Salinidad_E9\n",
      "E9_Turbidez_E9\n",
      "E9_Temperatura_E9\n",
      "E9_Clorofila_E9\n",
      "E9_OxigenoDisuelto_E9\n",
      "E8_OxigenoDisuelto_E8\n",
      "E8_Clorofila_E8\n",
      "E8_Salinidad_E8\n",
      "E8_Turbidez_E8\n",
      "E8_Temperatura_E8\n",
      "E7_Clorofila_E7\n",
      "E7_Turbidez_E7\n",
      "E7_Temperatura_E7\n",
      "E7_OxigenoDisuelto_E7\n",
      "E7_Salinidad_E7\n",
      "E4_OxigenoDisuelto_E4\n",
      "E4_Salinidad_E4\n",
      "E4_Temperatura_E4\n",
      "E4_Turbidez_E4\n",
      "E4_Clorofila_E4\n",
      "E3_modificada_Temperatura_E3_modified\n",
      "E3_modificada_OxigenoDisuelto_E3_modified\n",
      "E3_modificada_Clorofila_E3\n",
      "E3_modificada_Salinidad_E3_modified\n",
      "E3_modificada_Turbidez_E3_modified\n",
      "E2_Temperatura_E2\n",
      "E2_Turbidez_E2\n",
      "E2_Clorofila_E2\n",
      "E2_Salinidad_E2\n",
      "E2_OxigenoDisuelto_E2\n",
      "E10_OxigenoDisuelto_E10\n",
      "E10_Temperatura_E10\n",
      "E10_Salinidad_E10\n",
      "E10_Clorofila_E10\n",
      "E10_Turbidez_E10\n",
      "E6_OxigenoDisuelto_E6\n",
      "E6_Turbidez_E6\n",
      "E6_Clorofila_E6\n",
      "E6_Temperatura_E6\n",
      "E6_Salinidad_E6\n",
      "E1_Clorofila_E1\n",
      "E1_Salinidad_E1\n",
      "E1_OxigenoDisuelto_E1\n",
      "E1_Turbidez_E1\n",
      "E1_Temperatura_E1\n",
      "E11_Turbidez_E11\n",
      "E11_Temperatura_E11\n",
      "E11_Clorofila_E11\n",
      "E11_OxigenoDisuelto_E11\n",
      "E11_Salinidad_E11\n"
     ]
    }
   ],
   "source": [
    "# dataframes_boyas: dict con claves tipo 'E3_Temperature_E3_UPCT' y valores DataFrames\n",
    "# Cada DF tiene columnas: 'Date', 'Depth_-0.5m', 'Depth_-1m', ... (las que existan)\n",
    "\n",
    "# Expresión regular para la columna de profundidad\n",
    "reg_depth = re.compile(r'^Depth_(-?\\d+(?:\\.\\d+)?)m$')\n",
    "\n",
    "# Lista vacía para ir guardando filas\n",
    "registros = []\n",
    "\n",
    "for key, df in dataframes_boyas.items():\n",
    "    print(key)\n",
    "    # 1) Extrae la variable del nombre de la clave\n",
    "    #    Asumiendo estructura 'BOYA_Variable_...'\n",
    "    partes = key.split('_')\n",
    "    if len(partes) < 2 or 'Date' not in df.columns:\n",
    "        continue\n",
    "    # Extraemos el nombre de la variable (Chl, Temp, OD, etc)\n",
    "    variable = partes[1]\n",
    "\n",
    "    # 2) Aseguramos fechas como datetime\n",
    "    dfi = df.copy()\n",
    "    dfi['Date'] = pd.to_datetime(dfi['Date'], errors='coerce')\n",
    "    dfi = dfi.dropna(subset=['Date'])\n",
    "\n",
    "    # 3) Selecciona columnas de profundidad tipo 'Depth_-0.5m'\n",
    "    depth_cols = [c for c in dfi.columns if reg_depth.match(c)]\n",
    "\n",
    "    if not depth_cols:\n",
    "        continue\n",
    "\n",
    "    # 4) Pasa a formato largo - para poder hacer operaciones por variable y por profundidad\n",
    "    # Así tendremos solamente estas cuatro columnas\n",
    "    long = dfi.melt(\n",
    "        id_vars='Date',\n",
    "        value_vars=depth_cols,\n",
    "        var_name='depth_col',\n",
    "        value_name='value'\n",
    "    )\n",
    "\n",
    "    # 5) Extrae la profundidad numérica\n",
    "    long['depth'] = long['depth_col'].str.extract(r'Depth_(-?\\d+(?:\\.\\d+)?)m').astype(float)\n",
    "\n",
    "    # Asignar variable\n",
    "    long['variable'] = variable\n",
    "\n",
    "    # 6) Guardamos filas válidas\n",
    "    registros.append(long[['Date', 'variable', 'depth', 'value']])\n",
    "\n",
    "# 7) Concatena todo\n",
    "if registros:\n",
    "    datos = pd.concat(registros, ignore_index=True)\n",
    "\n",
    "    # 8) Agrega por (variable, profundidad, fecha):\n",
    "    #    si hay múltiples muestras ese día (por la misma o distintas boyas), saca la media.\n",
    "    try:\n",
    "        agregada = (\n",
    "            datos\n",
    "            .groupby(['variable', 'depth', 'Date'], as_index=False, observed=True)['value']\n",
    "            .mean().round(2)\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Error al agrupar en {key}: {type(e).__name__} → {e}\")\n",
    "\n",
    "    # Profundidades que usamos como columnas\n",
    "    depths_obj = [-0.5, -1.0, -1.5, -2.0, -2.5, -3.0, -3.5, -4.0, -4.5]\n",
    "\n",
    "    # Crear un DataFrame por variable\n",
    "    dfs_por_variable = {}\n",
    "    for var, df_var in agregada.groupby('variable'):\n",
    "        # Para volver al formato ancho pero habiendo hecho la agregación, y las fechas pasan a ser el índice, y cada profundidad será una colmna\n",
    "        piv = df_var.pivot(index='Date', columns='depth', values='value')\n",
    "\n",
    "        # 1) Unión de fechas disponibles para esa variable (de la tabla ya agregada)\n",
    "        fechas_union = pd.Index(sorted(df_var['Date'].unique()))\n",
    "        #Reindex para garantizar que aparezcan todas las fechas\n",
    "        piv = piv.reindex(index=fechas_union)\n",
    "\n",
    "        # 2) Reindexa columnas a las profundidades objetivo: las que falten quedarán como NaN\n",
    "        piv = piv.reindex(columns=depths_obj)\n",
    "\n",
    "        piv.index.name = 'Date'  \n",
    "        df_final = piv.reset_index()\n",
    "\n",
    "        # 3) Ordenamos las columnas como: -0.5, -1.0, ...\n",
    "        # (ya están en ese orden; si no, reordena)\n",
    "        piv = piv[depths_obj]\n",
    "\n",
    "        # 4) Quitamos nombres de ejes y convierte Date a columna\n",
    "        piv.columns.name = None\n",
    "        df_final = piv.reset_index()  # primera col: Date\n",
    "\n",
    "        dfs_por_variable[var] = df_final\n",
    "\n",
    "        # Guardamos un csv por variable:\n",
    "        df_final.to_csv(f\"boyasRevisadas/{var}_series.csv\", index=False)\n",
    "\n",
    "else:\n",
    "    dfs_por_variable = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>-0.5</th>\n",
       "      <th>-1.0</th>\n",
       "      <th>-1.5</th>\n",
       "      <th>-2.0</th>\n",
       "      <th>-2.5</th>\n",
       "      <th>-3.0</th>\n",
       "      <th>-3.5</th>\n",
       "      <th>-4.0</th>\n",
       "      <th>-4.5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-08-02</td>\n",
       "      <td>45.93</td>\n",
       "      <td>45.57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-08-04</td>\n",
       "      <td>46.38</td>\n",
       "      <td>46.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.92</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-08-09</td>\n",
       "      <td>46.34</td>\n",
       "      <td>45.79</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.72</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-08-25</td>\n",
       "      <td>46.50</td>\n",
       "      <td>46.42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-08-30</td>\n",
       "      <td>46.83</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>2024-06-18</td>\n",
       "      <td>43.34</td>\n",
       "      <td>43.28</td>\n",
       "      <td>43.53</td>\n",
       "      <td>43.80</td>\n",
       "      <td>43.84</td>\n",
       "      <td>43.91</td>\n",
       "      <td>43.93</td>\n",
       "      <td>43.93</td>\n",
       "      <td>43.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>2024-06-25</td>\n",
       "      <td>42.78</td>\n",
       "      <td>44.03</td>\n",
       "      <td>43.91</td>\n",
       "      <td>44.08</td>\n",
       "      <td>44.11</td>\n",
       "      <td>44.52</td>\n",
       "      <td>44.74</td>\n",
       "      <td>44.17</td>\n",
       "      <td>43.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>2024-07-03</td>\n",
       "      <td>43.39</td>\n",
       "      <td>43.49</td>\n",
       "      <td>43.59</td>\n",
       "      <td>43.58</td>\n",
       "      <td>43.93</td>\n",
       "      <td>44.27</td>\n",
       "      <td>44.32</td>\n",
       "      <td>44.31</td>\n",
       "      <td>44.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>2024-07-09</td>\n",
       "      <td>43.99</td>\n",
       "      <td>43.81</td>\n",
       "      <td>44.16</td>\n",
       "      <td>43.34</td>\n",
       "      <td>43.64</td>\n",
       "      <td>43.82</td>\n",
       "      <td>43.93</td>\n",
       "      <td>44.02</td>\n",
       "      <td>44.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>2024-07-18</td>\n",
       "      <td>44.34</td>\n",
       "      <td>44.42</td>\n",
       "      <td>44.51</td>\n",
       "      <td>44.54</td>\n",
       "      <td>44.60</td>\n",
       "      <td>44.56</td>\n",
       "      <td>44.65</td>\n",
       "      <td>44.70</td>\n",
       "      <td>44.83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>425 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date   -0.5   -1.0   -1.5   -2.0   -2.5   -3.0   -3.5   -4.0   -4.5\n",
       "0   2016-08-02  45.93  45.57    NaN  45.57    NaN    NaN    NaN    NaN    NaN\n",
       "1   2016-08-04  46.38  46.00    NaN  45.92    NaN    NaN    NaN    NaN    NaN\n",
       "2   2016-08-09  46.34  45.79    NaN  45.72    NaN    NaN    NaN    NaN    NaN\n",
       "3   2016-08-25  46.50  46.42    NaN  46.40    NaN    NaN    NaN    NaN    NaN\n",
       "4   2016-08-30  46.83    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN\n",
       "..         ...    ...    ...    ...    ...    ...    ...    ...    ...    ...\n",
       "420 2024-06-18  43.34  43.28  43.53  43.80  43.84  43.91  43.93  43.93  43.64\n",
       "421 2024-06-25  42.78  44.03  43.91  44.08  44.11  44.52  44.74  44.17  43.97\n",
       "422 2024-07-03  43.39  43.49  43.59  43.58  43.93  44.27  44.32  44.31  44.30\n",
       "423 2024-07-09  43.99  43.81  44.16  43.34  43.64  43.82  43.93  44.02  44.02\n",
       "424 2024-07-18  44.34  44.42  44.51  44.54  44.60  44.56  44.65  44.70  44.83\n",
       "\n",
       "[425 rows x 10 columns]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs_por_variable[\"Salinidad\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nitrates",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
